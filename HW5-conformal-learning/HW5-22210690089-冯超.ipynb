{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1：使用 Conformal Learning 求解回归问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 faithful.dat 数据集，两列数据分别为喷发时间和等待时间\n",
    "df = pd.read_csv('./P1/faithful.dat', delimiter='\\s+').reset_index(drop=True)\n",
    "# 选取数据集的前100行作为训练集\n",
    "train_df = df.iloc[:100, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 nearest neighbor 计算 nonconformity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonconformity_scores(train_df):\n",
    "    x = train_df[\"eruptions\"].values.reshape(-1, 1)\n",
    "    y = train_df[\"waiting\"].values.reshape(-1, 1)\n",
    "    # 计算 x 之间的距离矩阵\n",
    "    distance = cdist(x, x, \"euclidean\")\n",
    "    # 将对角线元素设为无穷大\n",
    "    np.fill_diagonal(distance, np.inf)\n",
    "    # 找到每一行的最小值\n",
    "    min_distance = np.min(distance, axis=1)\n",
    "    # 找到每一行的最小值的索引\n",
    "    min_index_row, min_index_column = np.where(distance == min_distance[:, None])\n",
    "    min_dict = {\n",
    "        key: [val for i, val in enumerate(min_index_column) if min_index_row[i] == key]\n",
    "        for key in set(min_index_row)\n",
    "    }\n",
    "    # 计算离每个样本最近的样本的 y 的中位数，做差后计算绝对值，作为 nonconformity score\n",
    "    nonconformity_scores = []\n",
    "    for i in range(train_df.shape[0]):\n",
    "        nonconformity_scores.append(abs(y[i] - np.median(y[min_dict[i]]))[0])\n",
    "    return nonconformity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算每个新样本的 prediction interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_interval(train_df, new_x, level):\n",
    "    # 计算训练样本的 nonconformity score\n",
    "    nonconformity_scores = get_nonconformity_scores(train_df)\n",
    "    # 计算新样本的与训练样本的距离的最小值\n",
    "    min_distance = np.min(\n",
    "        abs(train_df[\"eruptions\"].values.reshape(-1, 1) - new_x), axis=0\n",
    "    )\n",
    "    # 找到最小值的索引\n",
    "    min_index = np.where(\n",
    "        abs(train_df[\"eruptions\"].values.reshape(-1, 1) - new_x) == min_distance\n",
    "    )[0]\n",
    "    # 计算新样本的预测值\n",
    "    prediction = np.median(train_df[\"waiting\"].values[min_index])\n",
    "    # 计算 nonconformity scores 的 level 分位数，即保证有 1 - level 的样本的 nonconformity score 大于等于该值\n",
    "    nonconformity_score_at_level = nonconformity_scores[\n",
    "        np.argsort(nonconformity_scores)[::-1][\n",
    "            int((1 - level) * len(nonconformity_scores))\n",
    "        ]\n",
    "    ]\n",
    "    # 计算新样本的 predition interval\n",
    "    lower_bound = prediction - nonconformity_score_at_level\n",
    "    upper_bound = prediction + nonconformity_score_at_level\n",
    "    return lower_bound, upper_bound"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算不同置信度下的预测准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 90.00%, correct rate: 86.05%\n",
      "level: 80.00%, correct rate: 79.07%\n",
      "level: 60.00%, correct rate: 51.16%\n"
     ]
    }
   ],
   "source": [
    "level_list = [0.9, 0.8, 0.6]\n",
    "for level in level_list:\n",
    "    count = 0\n",
    "    for i in range(100, df.shape[0]):\n",
    "        lower_bound, upper_bound = get_prediction_interval(train_df, df[\"eruptions\"].iloc[i], level)\n",
    "        if df[\"waiting\"].iloc[i] > lower_bound and df[\"waiting\"].iloc[i] < upper_bound:\n",
    "            count += 1\n",
    "    correct_rate = count / (i - 100 + 1)\n",
    "    print(\"level: {:.2%}, correct rate: {:.2%}\".format(level, correct_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在不同置信度下，预测准确率大致略低于置信度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2：使用 Conformal Learning 求解多标签分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取 glass.data 数据集\n",
    "df = pd.read_csv('./P2/glass.data', delimiter=',', header=None, index_col=0)\n",
    "# 创建标准化器对象\n",
    "scaler = StandardScaler()\n",
    "# 随机选择 150 个样本作为训练集\n",
    "train_df = df.sample(n=150, random_state=0)\n",
    "# 对自变量进行标准化\n",
    "train_df.iloc[:, :-1] = scaler.fit_transform(train_df.iloc[:, :-1])\n",
    "# 剩下的样本作为测试集\n",
    "test_df = df.drop(train_df.index)\n",
    "# 对自变量进行标准化\n",
    "test_df.iloc[:, :-1] = scaler.transform(test_df.iloc[:, :-1])\n",
    "# 重新索引\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基于 nearest neighbor 计算 nonconformity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonconformity_scores(train_df, new_x, new_y):\n",
    "    x = pd.concat([train_df.iloc[:, :-1], new_x.to_frame().T], axis=0).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    y = pd.concat([train_df.iloc[:, -1], pd.Series([new_y])]).reset_index(drop=True)\n",
    "    # 计算 x 之间的距离矩阵\n",
    "    distance = cdist(x, x, \"euclidean\")\n",
    "    # 将对角线元素设为无穷大\n",
    "    np.fill_diagonal(distance, np.inf)\n",
    "    # 计算相同标签的最小距离和不同标签的最小距离的比值，作为 nonconformity score\n",
    "    nonconformity_scores = []\n",
    "    for i in range(x.shape[0]):\n",
    "        # 找到第 i 行中，与样本 i 标签相同的所有样本，并求其距离的最小值\n",
    "        min_distance_with_same_label = np.min(distance[i, y == y[i]])\n",
    "        # 找到第 i 行中，与样本 i 标签不同的所有样本，并求其距离的最小值\n",
    "        min_distance_with_different_label = np.min(distance[i, y != y[i]])\n",
    "        # 计算第 i 行的 nonconformity score\n",
    "        nonconformity_score = (\n",
    "            min_distance_with_same_label / min_distance_with_different_label\n",
    "        )\n",
    "        nonconformity_scores.append(nonconformity_score)\n",
    "    return nonconformity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算每个新样本的 prediction set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_set(train_df, new_x, level):\n",
    "    # 遍历所有可能的标签值，计算新样本在该标签下的 p value\n",
    "    p_values = []\n",
    "    labels = list(set(train_df.iloc[:, -1]))\n",
    "    for label in labels:\n",
    "        # 计算训练样本的 nonconformity scores\n",
    "        nonconformity_scores = get_nonconformity_scores(train_df, new_x, label)\n",
    "        # 计算新样本的 nonconformity score 在训练样本中的排名\n",
    "        rank = sum(nonconformity_scores >= nonconformity_scores[-1])\n",
    "        # 计算 p value\n",
    "        p_value = rank / len(nonconformity_scores)\n",
    "        p_values.append(p_value)\n",
    "    # 找到 p value 大于 1 - level 的标签\n",
    "    prediction_set = [labels[i] if p_values[i] > 1 - level else None for i in range(len(p_values))]\n",
    "    # 去掉 None\n",
    "    prediction_set = [i for i in prediction_set if i is not None]\n",
    "    return prediction_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算不同置信度下的预测准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level: 90.00%, correct rate: 90.62%\n",
      "level: 80.00%, correct rate: 76.56%\n",
      "level: 60.00%, correct rate: 57.81%\n"
     ]
    }
   ],
   "source": [
    "level_list = [0.9, 0.8, 0.6]\n",
    "for level in level_list:\n",
    "    count = 0\n",
    "    for i in range(test_df.shape[0]):\n",
    "        prediction_set = get_prediction_set(train_df, test_df.iloc[i, :-1], level)\n",
    "        if test_df.iloc[i, -1] in prediction_set:\n",
    "            count += 1\n",
    "    correct_rate = count / test_df.shape[0]\n",
    "    print(\"level: {:.2%}, correct rate: {:.2%}\".format(level, correct_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在不同置信度下，预测准确率与置信度十分相近。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
